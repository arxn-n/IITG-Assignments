{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport random\nimport glob\nimport cv2\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import backend as K\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-25T15:05:22.622283Z","iopub.execute_input":"2021-09-25T15:05:22.622523Z","iopub.status.idle":"2021-09-25T15:05:27.846931Z","shell.execute_reply.started":"2021-09-25T15:05:22.622456Z","shell.execute_reply":"2021-09-25T15:05:27.846088Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"EPOCHS=20\nBATCH_SIZE=32\nHEIGHT=256\nWIDTH=256\nCHANNELS=3\nN_CLASSES=13\nAUTO = tf.data.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:05:39.651336Z","iopub.execute_input":"2021-09-25T15:05:39.651916Z","iopub.status.idle":"2021-09-25T15:05:39.656190Z","shell.execute_reply.started":"2021-09-25T15:05:39.651879Z","shell.execute_reply":"2021-09-25T15:05:39.655407Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Utility functions","metadata":{}},{"cell_type":"code","source":"def loadImage(path):\n    img = Image.open(path)\n    img = np.array(img)\n    \n    image = img[:,:256]\n    image = image / 255.0\n    mask = img[:,256:]\n    \n    return image, mask\n\ndef bin_image(mask):\n    bins = np.array([20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240])\n    new_mask = np.digitize(mask, bins)\n    return new_mask\n\ndef getSegmentationArr(image, classes, width=WIDTH, height=HEIGHT):\n    seg_labels = np.zeros((height, width, classes))\n    img = image[:, : , 0]\n\n    for c in range(classes):\n        seg_labels[:, :, c] = (img == c ).astype(int)\n    return seg_labels\n\ndef give_color_to_seg_img(seg, n_classes=N_CLASSES):\n    \n    seg_img = np.zeros( (seg.shape[0],seg.shape[1],3) ).astype('float')\n    colors = sns.color_palette(\"hls\", n_classes)\n    \n    for c in range(n_classes):\n        segc = (seg == c)\n        seg_img[:,:,0] += (segc*( colors[c][0] ))\n        seg_img[:,:,1] += (segc*( colors[c][1] ))\n        seg_img[:,:,2] += (segc*( colors[c][2] ))\n\n    return(seg_img)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:05:53.761461Z","iopub.execute_input":"2021-09-25T15:05:53.761914Z","iopub.status.idle":"2021-09-25T15:05:53.777414Z","shell.execute_reply.started":"2021-09-25T15:05:53.761878Z","shell.execute_reply":"2021-09-25T15:05:53.775760Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_folder = \"../input/cityscapes-image-pairs/cityscapes_data/train\"\nvalid_folder = \"../input/cityscapes-image-pairs/cityscapes_data/val\"\ntrain_filenames = glob.glob(os.path.join(train_folder, \"*.jpg\"))\nvalid_filenames = glob.glob(os.path.join(valid_folder, \"*.jpg\"))\n\nnum_of_training_samples = len(train_filenames) \nnum_of_valid_samples = len(valid_filenames)\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, filenames,\n                 batch_size=BATCH_SIZE,\n                 shuffle=True):\n\n        self.filenames = filenames\n        self.batch_size = BATCH_SIZE\n        self.shuffle= shuffle\n        self.n = len(self.filenames)\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            random.shuffle(self.filenames)\n\n    def __get_data(self, batches):\n        imgs=[]\n        segs=[]\n        for file in batches:\n            image, mask = loadImage(file)\n            mask_binned = bin_image(mask)\n            labels = getSegmentationArr(mask_binned, N_CLASSES)\n            labels = np.argmax(labels, axis=-1)\n\n            imgs.append(image)\n            segs.append(labels)\n\n        return np.array(imgs), np.array(segs)\n\n    def __getitem__(self, index):\n\n        batches = self.filenames[index * self.batch_size:(index + 1) * self.batch_size]\n\n        X, y = self.__get_data(batches)\n\n        return (X, y)\n\n    def __len__(self):\n\n        return self.n // self.batch_size","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:05:58.900006Z","iopub.execute_input":"2021-09-25T15:05:58.900694Z","iopub.status.idle":"2021-09-25T15:05:59.502362Z","shell.execute_reply.started":"2021-09-25T15:05:58.900659Z","shell.execute_reply":"2021-09-25T15:05:59.501612Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_gen = DataGenerator(train_filenames)\nval_gen = DataGenerator(valid_filenames)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:06:04.798850Z","iopub.execute_input":"2021-09-25T15:06:04.799149Z","iopub.status.idle":"2021-09-25T15:06:04.803676Z","shell.execute_reply.started":"2021-09-25T15:06:04.799119Z","shell.execute_reply":"2021-09-25T15:06:04.802616Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"for imgs, segs in train_gen:\n    break\nimgs.shape, segs.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:06:08.593728Z","iopub.execute_input":"2021-09-25T15:06:08.594291Z","iopub.status.idle":"2021-09-25T15:06:09.209950Z","shell.execute_reply.started":"2021-09-25T15:06:08.594254Z","shell.execute_reply":"2021-09-25T15:06:09.209302Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"image = imgs[0]\nmask = give_color_to_seg_img(segs[0])\nmasked_image = image * 0.5 + mask * 0.5\n\nfig, axs = plt.subplots(1, 3, figsize=(20,20))\naxs[0].imshow(image)\naxs[0].set_title('Original Image')\naxs[1].imshow(mask)\naxs[1].set_title('Segmentation Mask')\n#predimg = cv2.addWeighted(imgs[i]/255, 0.6, _p, 0.4, 0)\naxs[2].imshow(masked_image)\naxs[2].set_title('Masked Image')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:06:11.923208Z","iopub.execute_input":"2021-09-25T15:06:11.923498Z","iopub.status.idle":"2021-09-25T15:06:12.472255Z","shell.execute_reply.started":"2021-09-25T15:06:11.923469Z","shell.execute_reply":"2021-09-25T15:06:12.471591Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Loss function","metadata":{}},{"cell_type":"code","source":"smooth = 1\n\ndef dice_coef(y_true, y_pred):\n    And = tf.reduce_sum(y_true * y_pred)\n    return (2 * And + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = tf.reduce_sum(y_true * y_pred)\n    sum_ = tf.reduce_sum(y_true + y_pred)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return jac\n\ndef jac_distance(y_true, y_pred):\n    return 1 - iou(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:06:16.400477Z","iopub.execute_input":"2021-09-25T15:06:16.401082Z","iopub.status.idle":"2021-09-25T15:06:16.407711Z","shell.execute_reply.started":"2021-09-25T15:06:16.401022Z","shell.execute_reply":"2021-09-25T15:06:16.406986Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    p = MaxPooling2D((2, 2))(c)\n    return c, p\n\ndef up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    us = UpSampling2D((2, 2))(x)\n    concat = Concatenate()([us, skip])\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    return c\n\ndef bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    return c","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:06:21.760851Z","iopub.execute_input":"2021-09-25T15:06:21.761516Z","iopub.status.idle":"2021-09-25T15:06:21.771578Z","shell.execute_reply.started":"2021-09-25T15:06:21.761480Z","shell.execute_reply":"2021-09-25T15:06:21.769602Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def UNet():\n    f = [16, 32, 64, 128, 256]\n    inputs = Input((HEIGHT,WIDTH,3))\n    \n    p0 = inputs\n    c1, p1 = down_block(p0, f[0]) #128 -> 64\n    c2, p2 = down_block(p1, f[1]) #64 -> 32\n    c3, p3 = down_block(p2, f[2]) #32 -> 16\n    c4, p4 = down_block(p3, f[3]) #16->8\n    \n    bn = bottleneck(p4, f[4])\n    \n    u1 = up_block(bn, c4, f[3]) #8 -> 16\n    u2 = up_block(u1, c3, f[2]) #16 -> 32\n    u3 = up_block(u2, c2, f[1]) #32 -> 64\n    u4 = up_block(u3, c1, f[0]) #64 -> 128\n    \n    outputs = Conv2D(13, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n    model = Model(inputs, outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:06:27.005775Z","iopub.execute_input":"2021-09-25T15:06:27.006104Z","iopub.status.idle":"2021-09-25T15:06:27.024173Z","shell.execute_reply.started":"2021-09-25T15:06:27.006053Z","shell.execute_reply":"2021-09-25T15:06:27.023414Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def unet():\n    main_input = Input(shape=(HEIGHT, WIDTH, CHANNELS), name = 'img_input')\n\n    ''' ~~~~~~~~~~~~~~~~~~~ ENCODING LAYERS ~~~~~~~~~~~~~~~~~~~ '''\n\n    c1 = Conv2D(32, kernel_size=(3,3), padding = 'same')(main_input)\n    c1 = LeakyReLU(0.2)(c1)\n    c1 = BatchNormalization()(c1)\n    c1 = Conv2D(32, kernel_size=(3,3), padding = 'same')(c1)\n    c1 = LeakyReLU(0.2)(c1)\n    c1 = BatchNormalization()(c1)\n\n    p1 = MaxPooling2D((2,2))(c1)\n\n    c2 = Conv2D(32*2, kernel_size=(3,3), padding = 'same')(p1)\n    c2 = LeakyReLU(0.2)(c2)\n    c2 = BatchNormalization()(c2)\n    c2 = Conv2D(32*2, kernel_size=(3,3), padding = 'same')(c2)\n    c2 = LeakyReLU(0.2)(c2)\n    c2 = BatchNormalization()(c2)\n\n    p2 = MaxPooling2D((2,2))(c2)\n\n    c3 = Conv2D(32*4, kernel_size=(3,3), padding = 'same')(p2)\n    c3 = LeakyReLU(0.2)(c3)\n    c3 = BatchNormalization()(c3)\n    c3 = Conv2D(32*2, kernel_size=(1,1), padding = 'same')(c3)\n    c3 = LeakyReLU(0.2)(c3)\n    c3 = BatchNormalization()(c3)\n    c3 = Conv2D(32*4, kernel_size=(3,3), padding = 'same')(c3)\n    c3 = LeakyReLU(0.2)(c3)\n    c3 = BatchNormalization()(c3)\n\n    p3 = MaxPooling2D((2,2))(c3)\n\n    c4 = Conv2D(32*6, kernel_size=(3,3), padding = 'same')(p3)\n    c4 = LeakyReLU(0.2)(c4)\n    c4 = BatchNormalization()(c4)\n    c4 = Conv2D(32*4, kernel_size=(1,1), padding = 'same')(c4)\n    c4 = LeakyReLU(0.2)(c4)\n    c4 = BatchNormalization()(c4)\n    c4 = Conv2D(32*6, kernel_size=(3,3), padding = 'same')(c4)\n    c4 = LeakyReLU(0.2)(c4)\n    c4 = BatchNormalization()(c4)\n\n    p4 = MaxPooling2D((2,2))(c4)\n\n    c5 = Conv2D(32*6, kernel_size=(3,3), padding = 'same')(p4)\n    c5 = LeakyReLU(0.2)(c5)\n    c5 = BatchNormalization()(c5)\n\n\n    ''' ~~~~~~~~~~~~~~~~~~~ DECODING LAYERS ~~~~~~~~~~~~~~~~~~~ '''\n\n    u1 = UpSampling2D((2,2))(c5)\n    concat1 = concatenate([c4, u1])\n\n    c6 = Conv2D(32*4, kernel_size=(3,3), padding = 'same')(concat1)\n    c6 = LeakyReLU(0.2)(c6)\n    c6 = BatchNormalization()(c6)\n    c6 = Conv2D(32*4, kernel_size=(3,3), padding = 'same')(c6)\n    c6 = LeakyReLU(0.2)(c6)\n    c6 = BatchNormalization()(c6)\n\n\n    u2 = UpSampling2D((2,2))(c6)\n    concat2 = concatenate([c3, u2])\n\n    c7 = Conv2D(32*2, kernel_size=(3,3), padding = 'same')(concat2)\n    c7 = LeakyReLU(0.2)(c7)\n    c7 = BatchNormalization()(c7)\n    c7 = Conv2D(32*2, kernel_size=(3,3), padding = 'same')(c7)\n    c7 = LeakyReLU(0.2)(c7)\n    c7 = BatchNormalization()(c7)\n\n    u3 = UpSampling2D((2,2))(c7)\n    concat3 = concatenate([c2, u3])\n\n    c8 = Conv2D(32, kernel_size=(3,3), padding = 'same')(concat3)\n    c8 = LeakyReLU(0.2)(c8)\n    c8 = BatchNormalization()(c8)\n    c8 = Conv2D(32, kernel_size=(3,3), padding = 'same')(c8)\n    c8 = LeakyReLU(0.2)(c8)\n    c8 = BatchNormalization()(c8)\n\n    u4 = UpSampling2D((2,2))(c8)\n    concat4 = concatenate([c1, u4])\n\n    c9 = Conv2D(16, kernel_size = (1,1), padding = 'same')(concat4)\n    c9 = LeakyReLU(0.2)(c9)\n    c9 = BatchNormalization()(c9)\n\n    mask_out = Conv2D(N_CLASSES, (1,1), padding = 'same', activation = 'sigmoid', name = 'mask_out')(c9)\n\n    model = Model(inputs = [main_input], outputs = [mask_out])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:06:30.107467Z","iopub.execute_input":"2021-09-25T15:06:30.107923Z","iopub.status.idle":"2021-09-25T15:06:30.130988Z","shell.execute_reply.started":"2021-09-25T15:06:30.107874Z","shell.execute_reply":"2021-09-25T15:06:30.130079Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = unet()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:06:37.137589Z","iopub.execute_input":"2021-09-25T15:06:37.137867Z","iopub.status.idle":"2021-09-25T15:06:39.565383Z","shell.execute_reply.started":"2021-09-25T15:06:37.137822Z","shell.execute_reply":"2021-09-25T15:06:39.564680Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Callbacks","metadata":{}},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('seg_model.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:06:49.062106Z","iopub.execute_input":"2021-09-25T15:06:49.062717Z","iopub.status.idle":"2021-09-25T15:06:49.068338Z","shell.execute_reply.started":"2021-09-25T15:06:49.062681Z","shell.execute_reply":"2021-09-25T15:06:49.067371Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"## 20 epochs with Categorical Crossentropy loss","metadata":{}},{"cell_type":"code","source":"TRAIN_STEPS = len(train_gen)\nVAL_STEPS = len(val_gen)\n\nmodel.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\nhistory = model.fit(train_gen, validation_data=val_gen, steps_per_epoch=TRAIN_STEPS, \n          validation_steps=VAL_STEPS, epochs=EPOCHS, callbacks = [checkpoint])","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:06:54.102009Z","iopub.execute_input":"2021-09-25T15:06:54.102633Z","iopub.status.idle":"2021-09-25T15:23:13.611393Z","shell.execute_reply.started":"2021-09-25T15:06:54.102580Z","shell.execute_reply":"2021-09-25T15:23:13.610644Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## 10 epochs with lr 1e-4","metadata":{}},{"cell_type":"code","source":"learning_rate = 1e-4\ndecay_rate = (learning_rate - 1e-6) / 100\nopt = tf.keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\n\ncheckpoint = ModelCheckpoint('seg_model_v2.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\nmodel.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\nhistory2 = model.fit(train_gen, validation_data=val_gen, steps_per_epoch=TRAIN_STEPS, \n          validation_steps=VAL_STEPS, epochs=10, callbacks = [checkpoint])","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:24:19.675223Z","iopub.execute_input":"2021-09-25T15:24:19.675857Z","iopub.status.idle":"2021-09-25T15:32:20.259347Z","shell.execute_reply.started":"2021-09-25T15:24:19.675815Z","shell.execute_reply":"2021-09-25T15:32:20.258632Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Train History","metadata":{}},{"cell_type":"code","source":"loss = history.history[\"val_loss\"]\nacc = history.history[\"val_accuracy\"]\n\nplt.figure(figsize=(12, 10))\nplt.subplot(211)\nplt.title(\"Val. cce Loss\")\nplt.plot(loss)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\n\nplt.subplot(212)\nplt.title(\"Val. Accuracy\")\nplt.plot(acc)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:34:41.607678Z","iopub.execute_input":"2021-09-25T15:34:41.607958Z","iopub.status.idle":"2021-09-25T15:34:42.199632Z","shell.execute_reply.started":"2021-09-25T15:34:41.607929Z","shell.execute_reply":"2021-09-25T15:34:42.198945Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Visualize outputs","metadata":{}},{"cell_type":"code","source":"model.load_weights(\"./seg_model_v2.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:35:24.667250Z","iopub.execute_input":"2021-09-25T15:35:24.667524Z","iopub.status.idle":"2021-09-25T15:35:24.754692Z","shell.execute_reply.started":"2021-09-25T15:35:24.667497Z","shell.execute_reply":"2021-09-25T15:35:24.753965Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"test_gen = DataGenerator(valid_filenames, 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:35:28.472717Z","iopub.execute_input":"2021-09-25T15:35:28.472988Z","iopub.status.idle":"2021-09-25T15:35:28.476770Z","shell.execute_reply.started":"2021-09-25T15:35:28.472960Z","shell.execute_reply":"2021-09-25T15:35:28.476095Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"test_iter = iter(test_gen)\nfor i in range(12):\n    imgs, segs = next(test_iter)\n    pred = model.predict(imgs)\n    _p = give_color_to_seg_img(np.argmax(pred[0], axis=-1))\n    _s = give_color_to_seg_img(segs[0])\n\n    predimg = cv2.addWeighted(imgs[0], 0.5, _p, 0.5, 0)\n    trueimg = cv2.addWeighted(imgs[0], 0.5, _s, 0.5, 0)\n    \n    plt.figure(figsize=(12, 4))\n    plt.subplot(131)\n    plt.title(\"Original\")\n    plt.imshow(imgs[0])\n    plt.axis(\"off\")\n    \n    plt.subplot(132)\n    plt.title(\"Prediction\")\n    plt.imshow(predimg)\n    plt.axis(\"off\")\n    \n    plt.subplot(133)\n    plt.title(\"Ground truth\")\n    plt.imshow(trueimg)\n    plt.axis(\"off\")\n    plt.tight_layout()\n    plt.savefig(\"pred_\"+str(i)+\".png\", dpi=150)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:35:32.009486Z","iopub.execute_input":"2021-09-25T15:35:32.010034Z","iopub.status.idle":"2021-09-25T15:35:49.165739Z","shell.execute_reply.started":"2021-09-25T15:35:32.009999Z","shell.execute_reply":"2021-09-25T15:35:49.164994Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}